---
title: "Yelp Neural Network"
author: "Xinran Zhang"
date: ''
output:
  html_document:
    code_folding: show
    highlight: haddock
    number_sections: yes
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '4'
urlcolor: blue
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = T, cache.lazy = FALSE) # notice cache=T here
knitr::opts_chunk$set(fig.height=4, fig.width=7, fig.align = 'center', warning = F)

if(!require('pacman')) {
  install.packages('pacman')
}
pacman::p_load(keras, ggplot2, glmnet, RColorBrewer, wordcloud, neuralnet,
               plotly, latex2exp, data.table, randomForest)
```


\pagebreak

The Yelp dataset is 100000 previous reviews together with ratings. Use bag of words, each review is already processed in the term frequency format. There are  $p=1072$ words retained. The response variable is a binary `rating`, 1 being a good review and 0 being a bad review. 

We will implement a Neural Network model with two layers and varying number of neutrons.


## Data Preparation


```{r results=FALSE}
# Data prep
data2 <- fread("YELP_TM_freq.csv")  # fread the term freq tables
names(data2)[c(1:5, 500:510)] # notice that user_id, stars and date are in the data2
dim(data2)
data3 <- data2[, -c(1:3)]; dim(data3)# the first element is the rating
names(data3)[1:3]
levels(as.factor(data3$rating))

```

**Data preparation for NN**:

  + We split data into two sets: training data and validation
  + Training data will be split internally to tune any parameters
  + We reserve the validation data set to give an honest evaluation for the testing error.


**Validation data: `data3_val`**: reserve 10,000
```{r results='hide'}
# Split data
set.seed(1)  # for the purpose of reproducibility
n <- nrow(data3)
validation.index <- sample(n, 10000)
length(validation.index)   # reserve 10000
data3_val <- data3[validation.index, ] # 
## validation input/y
data3_xval <- as.matrix(data3_val[, -1])  # make sure it it is a matrix
data3_yval <- as.matrix(data3_val[, 1]) # make sure it it is a matrix
```

**Training data: `data3_xtrain`/`data3_ytrain`**: Use 90,000 as the training data. Internally we split this training data again to tune the parameters. Keras refer the split internal datasets as training/validation.

```{r}
## training input/y: need to be matrix/vector
data3_xtrain <- data3[-validation.index, -1]   #dim(data3_xtrain)
data3_ytrain <- data3[-validation.index, 1]   
data3_xtrain <- as.matrix(data3_xtrain) # make sure it it is a matrix
data3_ytrain <- as.matrix(data3_ytrain) # make sure it it is a matrix
```



### Fully Connected Neural Network

Now the data is prepared, let's begin working with our full dataset using the `keras` package.

The shape of the input is 1072 (the 1072 possible words in our frequency dictionary).

We use 16 neurons in the first layer and 8 neurons in the second layer. 

We use the *rectified linear unit* function as the activation function.

To set our output as a probability we specify the activation to be the "sigmoid" function.

**Define the Model/Architecture:**
  + two layers with 16 and 8 neurons in each layer
  + Activation function is `Relu`
  + Output layer is `Sigmoid`
  
```{r}
# set seed for keras
# set_random_seed(10)

p <- dim(data3_xtrain)[2] # number of input variables
model <- keras_model_sequential() %>%
  layer_dense(units = 16, activation = "relu", input_shape = c(p)) %>% 
  # 1 layer with 16 neurons. default activation is relu
  layer_dense(units = 8, activation = "relu") %>%  
  # layer 2 with 8 neurons
  layer_dense(units = 2, activation = "softmax") # output
print(model)
```

As we can see in the table above our model has a total of **17322** parameters:    

  + The input to the model are yelp reviews that are each coded as 1072 length sequences of frequencies. 
  + Our model's first layer is 16 nodes that are fully connected    
  + At each node a different set of weights $W's$ will be applied to each value of the 1072 word sequence to compute the weighted sum to which a bias will be added and then the activation function will be applied.  
  + These values will then flow to our second layer with (16+1)*8=136 where weights will be applied to each value and the weighted sum computed, the bias value will then be added and the activation function will then be applied 
  + The final layer which is output will have (8+1)*2=18 parameters
  + Combined our model with two layers and one final output, there are a total of 17168+136+18=17322 parameters across the model or architecture.   

Next we compile our model. We specify the optimizer logarithm we want to use ('rmsprop'), the loss function ('binary_crossentropy')  and the metric used to evaluate the performance (here we use accuracy which is the fraction of reviews that are correctly classified).

**Compile the Model**

```{r}
##Compile the Model
model %>% compile(
  optimizer = "rmsprop",
  loss = "sparse_categorical_crossentropy",
  metrics = c("accuracy")
)
```


```{r}
fit1 <- model %>% fit(
  data3_xtrain,
  data3_ytrain,
  epochs = 20,
  batch_size = 512,
  validation_split = .15 # set 15% of the data3_xtain, data3_ytrain as the validation data
)

plot(fit1)
```




**All 17323 parameters**

```{r}
weights <- model %>% get_weights()
# str(weights) # show each layers of W's and b's
# hist(weights[[1]])   # W^(1)
# weights[[2]] # b's for layer 1
```

**Predictions:**
Below are the predicted probabilities from the model for the first five values in our training set.
```{r}
round(model %>% predict(data3_xtrain[1:5,]), 3)
```

Lets see if we can manually compute these probabilities for the first five reviews in our training set using the computed weights shown previously.
```{r}
n5 <- 5

# first layer: z_1 = W_1 X + b_1; a_1 = ReLU(z_1)
z_1 <- data3_xtrain[1:n5, ] %*% weights[[1]] 
# add beta (weights[[2]]) to every row 
z_1 <- z_1 + matrix(rep(weights[[2]], n5), nrow = n5, byrow = T)
a_1 <- matrix(pmax(0, z_1), nrow = n5)

# second layer: z_2 = W_2 a_1 + b_2; a_2 = ReLU(z_2)
z_2 <- a_1 %*% weights[[3]]
z_2 <- z_2 + matrix(rep(weights[[4]], n5), nrow = n5, byrow = T)
a_2 <- matrix(pmax(0,  z_2), nrow = n5)

# output layer: softmax(W_3 a_2 + b_3)
z_out <- a_2 %*% weights[[5]] 
z_out <- z_out + matrix(rep(weights[[6]], n5), nrow = n5, byrow = T)
prob.pred <- t(apply(z_out, 1, function(z) exp(z)/sum(exp(z))))

round(prob.pred, 3)
```

The value computed by our loss function on our training data is as follows:
```{r}
fit1$metrics$loss[20]  # fit1$metrics keeps all the evaluations
```


### Tuning Parameter Selection  

From the graph below we see that by about 6 epochs our validation loss has bottomed out and we receive no further benefit from additional iterations

```{r}
plot(fit1)
```

To avoid overfitting lets use 6 epochs in our final model.

**Final training with all the training data:**

Here we have put all the steps together to get the final NN predictive equation
* Training data: data3_xtrain, data3_ytrain
* Validation data: data3_xvalidation, data3_yvalidation
* NN model:
  + two layers with 16 and 8 neurons in each layer
  + Activation function is `Relu`
  + Output layer is `Sigmoid`
* Epoch is 6


```{r}
p <- dim(data3_xtrain)[2] # number of input variables

#retain the nn:
model <- keras_model_sequential() %>%
  layer_dense(units = 16, activation = "relu", input_shape = c(p)) %>% 
  # 1 layer with 16 neurons. default activation is relu
  layer_dense(units = 8, activation = "relu") %>%  # layer 2 with 8 neurons
  layer_dense(units = 2, activation = "softmax") # output

model %>% compile(
  optimizer = "rmsprop",
  loss = "sparse_categorical_crossentropy",
  metrics = c("accuracy")
)

 model %>% fit(data3_xtrain, data3_ytrain, epochs = 6, batch_size = 512)
```


### Assessing Performance  

```{r warning=F, message=F}
results <- model %>% evaluate(data3_xval, data3_yval) ; results
```

Our accuracy on the validation data is an impressive 81% (19% of mis-classification error)! Meaning that we correctly classified 80% of the reviews as positive or negative.

### Prediction  

Finally we can do prediction. Let us see how well we predict the first 5 reviews in the validation data. 

**Get probabilities:**
```{r}
pred.prob <- model %>% predict(data3_xval[1:5,])
pred.prob
```

**Get the labels:**
```{r}
y.pred <- model %>% predict(data3_xval[1:5,]) %>% k_argmax() %>% as.integer() # majority vote!
data.frame(yhat=y.pred, y=data3_yval[1:5, 1])
```